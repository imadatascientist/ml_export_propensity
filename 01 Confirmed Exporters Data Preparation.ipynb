{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7bf8df61-c0e1-4769-b067-59b46e8e6161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f09f7657-4711-4db6-8c65-0fb004683e34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('select duns, date from workarea.us_expprop_exporters_build_201811')\n",
    "\n",
    "df = df.withColumn('date_preprocessed',  to_date(unix_timestamp(col('date'), 'MM/dd/yyyy').cast('timestamp')))\n",
    "\n",
    "df = df.withColumn('append_year', lit(None))\n",
    "df = df.withColumn('append_month', lit(9))\n",
    "df = df.withColumn('append_year', when(col('date_preprocessed') < lit(\"2017-10-01\"), 2016).otherwise(col('append_year')))\n",
    "df = df.withColumn('append_year', when(col('date_preprocessed') >= lit(\"2017-10-01\"), 2017).otherwise(col('append_year')))\n",
    "\n",
    "df = df.withColumn('export', lit(1))\n",
    "\n",
    "wblinkage = spark.sql('select duns_nbr as duns, phy_ctry_code as country_code, load_year as append_year, load_month as append_month from dnb_data_globalarea.wblinkage where load_year in (2016, 2017) and load_month = 9')\n",
    "wbusunlinked = spark.sql('select duns_nbr as duns, phy_ctry_code as country_code, load_year as append_year, load_month as append_month from dnb_data_globalarea.wbusunlinked where load_year in (2016, 2017) and load_month = 9')\n",
    "wbglobalunlinked = spark.sql('select duns_nbr as duns, phy_ctry_code as country_code, load_year as append_year, load_month as append_month from dnb_data_globalarea.wbglobalunlinked where load_year in (2016, 2017) and load_month = 9')\n",
    "\n",
    "wb = wblinkage.union(wbusunlinked).union(wbglobalunlinked)\n",
    "\n",
    "df2 = df.join(wb.dropDuplicates(['duns', 'append_year', 'append_month']), on = ['duns', 'append_year', 'append_month'], how = 'inner')\n",
    "\n",
    "df3 = df2.where('country_code = 805')\n",
    "\n",
    "df4 = df3.dropDuplicates(['duns', 'append_year', 'append_month'])\n",
    "\n",
    "df4[['duns', 'append_year', 'append_month', 'export']].write.mode('overwrite').saveAsTable('workarea.us_export_propensity_exporters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a08a48ac-e16a-4a91-8c2a-d8b865a6b154",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01 Confirmed Exporters Data Preparation",
   "notebookOrigID": 3973735592133180,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
