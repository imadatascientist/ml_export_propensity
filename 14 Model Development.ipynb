{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "05a21c29-7384-43de-8529-50ec9b39e149",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/sahayk/risk_ml_modeling_framework/feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "74b65256-44df-4c4d-9166-dbe49dd73a27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /users/sahayk/risk_ml_modeling_framework/random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "628eda79-2d1c-44be-be7e-bb43feaa7b72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/sahayk/risk_ml_modeling_framework/model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "14893b4a-5e80-483d-aaef-5e4e4fb91adb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def featureImportance(model, X):\n",
    "  feat_imp = pd.DataFrame(model.feature_importances_, index = X.columns)\n",
    "  feat_imp = feat_imp.reset_index()\n",
    "  feat_imp.columns = ['feature', 'feature_importance']\n",
    "  feat_imp = feat_imp.sort_values(by = 'feature_importance', ascending = False)\n",
    "  feat_imp['cumulative_feature_importance'] = feat_imp['feature_importance'].cumsum()\n",
    "\n",
    "  f = 'gain'\n",
    "  feat_gain = pd.DataFrame.from_dict(model.get_booster().get_score(importance_type = f), orient = 'index')\n",
    "  feat_gain = feat_gain.reset_index()\n",
    "  feat_gain.columns = ['feature', 'gain']\n",
    "\n",
    "  feat_imp = feat_imp.merge(feat_gain, on = 'feature', how = 'left')\n",
    "  feat_imp = feat_imp.sort_values('gain', ascending = False)\n",
    "  return feat_imp\n",
    "\n",
    "def formatKSReport(ks_report):\n",
    "  ks_report.columns = ['decile', 'min', 'max', 'event', 'non_event', 'total', 'event_rate', 'cumulative_event', 'cumulative_non_event', 'ks', 'max_ks', 'l_cumulative_event', 'cumulative_total', 'l_cumulative_total', 'area', 'cumulative_area', 'area_b', 'pi', 'gini', 'auc']\n",
    "  ks_report['max_ks'] = np.where(ks_report['max_ks'] == '<----', '<', ks_report['max_ks'])\n",
    "  ks_report['decile'] = ks_report['decile'] + 5\n",
    "  ks_report['cumulative_event'] = ks_report['cumulative_event']/100\n",
    "  ks_report['cumulative_non_event'] = ks_report['cumulative_non_event']/100\n",
    "  ks_report['ks'] = ks_report['ks']/100\n",
    "  return ks_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a883df89-b468-424f-b995-7249bac3c310",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_vars = [\n",
    "'duns',\n",
    "'totempl',\n",
    "'cpoints',\n",
    "'fspoints',\n",
    "'hi_cr_tot_amt',\n",
    "'inds_norm_pydx_scr',\n",
    "'facy_sq_ft_msmt',\n",
    "'ucc_flng_3yr_cnt',\n",
    "'hl_ceo_chg_code',\n",
    "'fam_mbr_cnt',\n",
    "'acct_cnt',\n",
    "'extl_url_on_hmpg_cnt',\n",
    "'res_pop_code',\n",
    "'tot_12_mo_acct',\n",
    "'tot_amt_owg_rcnt',\n",
    "'hi_cr_3_mo',\n",
    "'tot_12_mo_pastdue_acc',\n",
    "'mths_snc_hi_pdue',\n",
    "'pdx_12mth_curr',\n",
    "'tot_avg_past30p_12mths',\n",
    "'tot_avg_past90p_12mths',\n",
    "'spnd_buyers_12m',\n",
    "'spnd_min_wsfo_12m',\n",
    "'spnd_dx13_12m',\n",
    "'spnd_avapo_r_12m',\n",
    "'spnd_avapo_f_12m',\n",
    "'spnd_max_avapo_o_12m',\n",
    "'spnd_dllrs_o_12m',\n",
    "'spnd_dllrs_12m',\n",
    "'spnd_max_avapo_f_12m',\n",
    "'spnd_max_avapo_r_12m',\n",
    "'spnd_avapo_12m',\n",
    "'spnd_dx40_b_12m',\n",
    "'ba_count_info_src_12m',\n",
    "'ba_cr_activity_12m',\n",
    "'ba_cr_cat_insur_12m',\n",
    "'ba_cr_cat_marketing_12m',\n",
    "'ba_cr_stability_12m',\n",
    "'ba_sum_excl_12m',\n",
    "'ba_sum_info_gov_12m',\n",
    "'ba_cnt_cr_12m',\n",
    "'ba_cr_cat_other_12m',\n",
    "'ba_cr_cat_online_3m',\n",
    "'drp_npayexp_loc_decile',\n",
    "'drp_pexp_cr_loc_decile',\n",
    "'drp_paydex1_loc_decile',\n",
    "'drp_pslow90p_loc_decile',\n",
    "'drp_sales_loc_decile',\n",
    "'drp_tlp_score_loc_decile',\n",
    "'loc_avg_npayexp',\n",
    "'loc_avg_dol30pl',\n",
    "'location_growth_score',\n",
    "'loc_pct_rent_1',\n",
    "'loc_avg_sales',\n",
    "'loc_pct_hqbr_b',\n",
    "'loc_pct_hqbr_r',\n",
    "'loc_pct_hqbr_s',\n",
    "'loc_pct_comptype_g',\n",
    "'loc_pct_via3_robust',\n",
    "'chg_phon',\n",
    "'chg_tot_emp',\n",
    "'inq_sic50_inq_24m',\n",
    "'inq_inquirer_sic_6_60m',\n",
    "'inq_inquirer_sic_0_60m',\n",
    "'inq_inquirer_sic_9_60m',\n",
    "'inq_inquirer_sic_5_60m',\n",
    "'inq_sic47_inq_60m',\n",
    "'inq_inquiry_duns_48m',\n",
    "'gctrs_cnt_unq_customer_country',\n",
    "'gctrs_cnt_unq_yrs',\n",
    "'gctrs_ttl_signal_3yrs',\n",
    "'ind_gctrs_3yrs',\n",
    "'npayexp',\n",
    "'satis',\n",
    "'emplhere',\n",
    "'numpaydex7',\n",
    "'sales',\n",
    "'bnkrpt',\n",
    "'nnetwrthsign',\n",
    "'ngndr',\n",
    "'nlocn',\n",
    "'nimptexpt',\n",
    "'nbusowrp',\n",
    "'nrectyp',\n",
    "'sml_bus_ind',\n",
    "'public_ind',\n",
    "'womn_ownd_ind',\n",
    "'miny_ownd_ind',\n",
    "'univ_ind',\n",
    "'pydexvar',\n",
    "'lien_ind',\n",
    "'suits_ind',\n",
    "'judg_ind',\n",
    "'hca_pct_hcm',\n",
    "'ncomptype',\n",
    "'nloc',\n",
    "'location_cluster_score_k500',\n",
    "'sic4_score',\n",
    "'exp_prop_bus_nme_ind',\n",
    "'foreign_trade_buyer_ind',\n",
    "'export_job_title_ind',\n",
    "'sample_type',\n",
    "'export',\n",
    "'append_year',\n",
    "'append_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bc7d828f-8723-4b01-b4d6-eeed6c6dc8e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loc_scr_train_df = spark.sql('select duns, location_cluster_score1 as location_cluster_score_k500, append_year, append_month, export from workarea.us_export_propensity_analytic_dataset_train_location_cluster_score_derived_attribute_k500')\n",
    "loc_scr_val_df = spark.sql('select duns, location_cluster_score1 as location_cluster_score_k500, append_year, append_month, export from workarea.us_export_propensity_analytic_dataset_val_location_cluster_score_derived_attribute_k500')\n",
    "loc_scr_test_df = spark.sql('select duns, location_cluster_score1 as location_cluster_score_k500, append_year, append_month, export from workarea.us_export_propensity_analytic_dataset_test_location_cluster_score_derived_attribute_k500')\n",
    "\n",
    "loc_scr_train_df = loc_scr_train_df.toPandas()\n",
    "loc_scr_val_df = loc_scr_val_df.toPandas()\n",
    "loc_scr_test_df = loc_scr_test_df.toPandas()\n",
    "\n",
    "trade_train = spark.sql('select * from workarea.us_export_propensity_analytic_dataset_train_importer_derived_attribute')\n",
    "val_train = spark.sql('select * from workarea.us_export_propensity_analytic_dataset_val_importer_derived_attribute')\n",
    "test_train = spark.sql('select * from workarea.us_export_propensity_analytic_dataset_test_importer_derived_attribute')\n",
    "\n",
    "trade_train_df = trade_train.toPandas()\n",
    "val_train_df = val_train.toPandas()\n",
    "test_train_df = test_train.toPandas()\n",
    "\n",
    "train_jobtitle = spark.sql('select * from workarea.us_export_propensity_analytic_dataset_train_job_title_derived_attribute')\n",
    "val_jobtitle = spark.sql('select * from workarea.us_export_propensity_analytic_dataset_val_job_title_derived_attribute')\n",
    "test_jobtitle = spark.sql('select * from workarea.us_export_propensity_analytic_dataset_test_job_title_derived_attribute')\n",
    "\n",
    "train_jobtitle_df = train_jobtitle.toPandas()\n",
    "val_jobtitle_df = val_jobtitle.toPandas()\n",
    "test_jobtitle_df = test_jobtitle.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e3c0222b-755c-4c07-9d5b-a3d10bd29358",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/dbfs/FileStore/sahayk/us_export_propensity/input_data/us_export_propensity_data_prep_and_derivations.csv')\n",
    "\n",
    "df['ind_gctrs_3yrs'] = np.where(df['ind_gctrs_3yrs'] != 1, 0, df['ind_gctrs_3yrs'])\n",
    "\n",
    "df['weight'] = 1\n",
    "\n",
    "train = df[df['sample_type'] == 'train']\n",
    "val = df[df['sample_type'] == 'val']\n",
    "test = df[df['sample_type'] == 'test']\n",
    "\n",
    "train = pd.merge(train, loc_scr_train_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "val = pd.merge(val, loc_scr_val_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "test = pd.merge(test, loc_scr_test_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, trade_train_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "val = pd.merge(val, val_train_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "test = pd.merge(test, test_train_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, train_jobtitle_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "val = pd.merge(val, val_jobtitle_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "test = pd.merge(test, test_jobtitle_df, on = ['duns', 'append_year', 'append_month', 'export'], how = 'left')\n",
    "\n",
    "non_predictors = ['duns', 'export', 'sample_type', 'append_year', 'append_month', 'weight']\n",
    "predictors = list(set(input_vars) - set(non_predictors))\n",
    "\n",
    "train2 = train.copy()\n",
    "val2 = val.copy()\n",
    "test2 = test.copy()\n",
    "\n",
    "train2['drop_ind'] = np.where((train2['export'] == 1) & (train2['sic4_score'].isna()), 1, 0)\n",
    "val2['drop_ind'] = np.where((val2['export'] == 1) & (val2['sic4_score'].isna()), 1, 0)\n",
    "test2['drop_ind'] = np.where((test2['export'] == 1) & (test2['sic4_score'].isna()), 1, 0)\n",
    "\n",
    "train2 = train2[train2['drop_ind'] == 0]\n",
    "val2 = val2[val2['drop_ind'] == 0]\n",
    "test2 = test2[test2['drop_ind'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "06762acf-3eef-428e-b1aa-66c034f33c47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params = \"{'colsample_bylevel':np.random.randint(5,10)/10,'colsample_bytree':np.random.randint(5,10)/10,'learning_rate': np.random.choice([0.1 , 0.01 , 0.05 , 0.075]),'max_depth':np.random.randint(3,6),'min_child_weight':np.random.randint(3,10),'n_estimators': np.random.choice([300,400,500,600]),'subsample':np.random.randint(5,10)/10}\"\n",
    "\n",
    "rs = ks_search(100, params, train2[predictors], train2['export'], train2['weight'], val2[predictors], val2['export'], val2['weight'])\n",
    "\n",
    "rs.randomsearch_KS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ee472648-5950-4348-b473-7108a220c183",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_full = rs.result_out\n",
    "hyper_param = pd.concat(output_full)\n",
    "hyper_param.columns = ['train', 'val', 'diff', 'event_rate', 'min_prob', 'max_prob', 'predicted_event_rate', 'hyper_param', 'iteration', 'best_n_tree']\n",
    "\n",
    "random_search_result = pd.concat([hyper_param.drop(['hyper_param'], axis = 1), hyper_param['hyper_param'].map(eval).apply(pd.Series)], axis = 1).reset_index()\n",
    "random_search_result.columns = ['metric', 'train', 'val', 'diff', 'event_rate', 'min_prob', 'max_prob', 'predicted_event_rate', 'iteration', 'best_n_tree', 'colsample_bylevel', 'colsample_bytree', 'learning_rate', 'max_depth', 'min_child_weight', 'n_estimator', 'subsample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5437eb94-3ad6-416b-98de-26f1dae995f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model1 = xgb.XGBClassifier(colsample_bylevel = 0.6, colsample_bytree = 0.6, learning_rate = 0.075, max_depth = 3, min_child_weight = 9, n_estimators = 600, subsample = 0.5)\n",
    "\n",
    "model1.fit(train2[predictors], train2['export'], sample_weight = train2['weight'], eval_set = [(val2[predictors], val2['export'], val2['weight'])], eval_metric = 'auc', early_stopping_rounds = 8)\n",
    "\n",
    "feature_list = list(model1.get_booster().feature_names)\n",
    "\n",
    "train2['predicted_export'] = model1.predict_proba(train2[feature_list], ntree_limit = model1.best_ntree_limit)[:,1]\n",
    "val2['predicted_export'] = model1.predict_proba(val2[feature_list], ntree_limit = model1.best_ntree_limit)[:,1]\n",
    "test2['predicted_export'] = model1.predict_proba(test2[feature_list], ntree_limit = model1.best_ntree_limit)[:,1]\n",
    "\n",
    "feat_imp = featureImportance(model1, train2[feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "014d26cd-87df-4260-8c6f-cfefb192e164",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4d7d0a6c-6570-47e6-a915-bd1f725764b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ks = metrics(None, None, None, None, None, None)\n",
    "ks_report_train = ks.KS_train(train2['export'], train2['predicted_export'], train2['weight'], bins = 10)\n",
    "ks_report_val = ks.KS_train(val2['export'], val2['predicted_export'], val2['weight'], bins = 10)\n",
    "ks_report_test = ks.KS_train(test2['export'], test2['predicted_export'], test2['weight'], bins = 10)\n",
    "\n",
    "ks_report_train = formatKSReport(ks_report_train)\n",
    "ks_report_val = formatKSReport(ks_report_val)\n",
    "ks_report_test = formatKSReport(ks_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "87b58de4-8502-45f2-b4a0-d02823400fe0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "49e70402-2679-436a-98cd-fe55e7e31ac0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c3d43b60-e95b-478b-89c3-fc9d60199af6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e8c30fce-90eb-4ec3-8b49-7d28e417a477",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictors2 = list(feat_imp[feat_imp['cumulative_feature_importance'] <= 0.90]['feature'])\n",
    "\n",
    "params = \"{'colsample_bylevel':np.random.randint(5,10)/10,'colsample_bytree':np.random.randint(5,10)/10,'learning_rate': np.random.choice([0.1 , 0.01 , 0.05 , 0.075]),'max_depth':np.random.randint(3,5),'min_child_weight':np.random.randint(3,10),'n_estimators': np.random.choice([300,400,500]),'subsample':np.random.randint(5,10)/10}\"\n",
    "\n",
    "rs2 = ks_search(50, params, train2[predictors2], train2['export'], train2['weight'], val2[predictors2], val2['export'], val2['weight'])\n",
    "\n",
    "rs2.randomsearch_KS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a69cebfa-5d8d-4b84-b8bb-e69dbf71c0f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_full2 = rs2.result_out\n",
    "hyper_param2 = pd.concat(output_full2)\n",
    "hyper_param2.columns = ['train', 'val', 'diff', 'event_rate', 'min_prob', 'max_prob', 'predicted_event_rate', 'hyper_param', 'iteration', 'best_n_tree']\n",
    "\n",
    "random_search_result2 = pd.concat([hyper_param2.drop(['hyper_param'], axis = 1), hyper_param2['hyper_param'].map(eval).apply(pd.Series)], axis = 1).reset_index()\n",
    "random_search_result2.columns = ['metric', 'train', 'val', 'diff', 'event_rate', 'min_prob', 'max_prob', 'predicted_event_rate', 'iteration', 'best_n_tree', 'colsample_bylevel', 'colsample_bytree', 'learning_rate', 'max_depth', 'min_child_weight', 'n_estimator', 'subsample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "77137466-0194-40ea-9c8b-19673119a496",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model2 = xgb.XGBClassifier(colsample_bylevel = 0.7, colsample_bytree = 0.9, learning_rate = 0.05, max_depth = 4, min_child_weight = 9, n_estimators = 300, subsample = 0.7)\n",
    "\n",
    "model2.fit(train2[predictors2], train2['export'], sample_weight = train2['weight'], eval_set = [(val2[predictors2], val2['export'], val2['weight'])], eval_metric = 'auc', early_stopping_rounds = 8)\n",
    "\n",
    "feature_list2 = list(model2.get_booster().feature_names)\n",
    "\n",
    "train2['predicted_export2'] = model2.predict_proba(train2[feature_list2], ntree_limit = model2.best_ntree_limit)[:,1]\n",
    "val2['predicted_export2'] = model2.predict_proba(val2[feature_list2], ntree_limit = model2.best_ntree_limit)[:,1]\n",
    "test2['predicted_export2'] = model2.predict_proba(test2[feature_list2], ntree_limit = model2.best_ntree_limit)[:,1]\n",
    "\n",
    "feat_imp2 = featureImportance(model2, train2[feature_list2])\n",
    "\n",
    "display(feat_imp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "65b77cdd-34c3-4139-ae7e-e51119901a62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ks2 = metrics(None, None, None, None, None, None)\n",
    "ks_report_train2 = ks2.KS_train(train2['export'], train2['predicted_export2'], train2['weight'], bins = 10)\n",
    "ks_report_val2 = ks2.KS_train(val2['export'], val2['predicted_export2'], val2['weight'], bins = 10)\n",
    "ks_report_test2 = ks2.KS_train(test2['export'], test2['predicted_export2'], test2['weight'], bins = 10)\n",
    "\n",
    "ks_report_train2 = formatKSReport(ks_report_train2)\n",
    "ks_report_val2 = formatKSReport(ks_report_val2)\n",
    "ks_report_test2 = formatKSReport(ks_report_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4642b208-62f6-470c-9656-4fb42d8806fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1e2785d6-3ef9-413a-b8ac-61afc79a7103",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "03975699-56ea-42ea-a16f-cbd53a4e8154",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "00db0f17-80a1-4df2-9cf4-77e5b0a96870",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_final = train2[non_predictors + feature_list2 + ['predicted_export2']]\n",
    "val_final = val2[non_predictors + feature_list2 + ['predicted_export2']]\n",
    "test_final = test2[non_predictors + feature_list2 + ['predicted_export2']]\n",
    "\n",
    "final_features = list(feat_imp2['feature'])\n",
    "\n",
    "train_final['weight'] = 1\n",
    "fs = preprocess(train_final[final_features], train_final['export'],  train_final['weight'])\n",
    "fs.identify_all({'missing_threshold': 0.95, 'correlation_threshold': 0.90})\n",
    "\n",
    "binning_data = fs.iv_df.astype(str)\n",
    "binning_data.columns = ['variable_name', 'min_value', 'max_value', 'count', 'dist_count', 'event', 'event_rate', 'non_event', 'non_event_rate',\n",
    "                       'dist_event', 'dist_non_event', 'woe', 'force', 'iv_bin', 'iv_overall']\n",
    "binning_data2 = binning_data.drop(columns = 'force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "58cce8dd-1f2b-47c8-8707-fd476da5e98b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_ks_list = []\n",
    "val_ks_list = []\n",
    "train_gini_list = []\n",
    "val_gini_list = []\n",
    "for i in list(train_final[predictors2].columns):\n",
    "  print(\"[INFO] Variable Name: {}\".format(i))\n",
    "  train_tmp = train_final[~train_final[i].isna()]\n",
    "  val_tmp = val_final[~val_final[i].isna()]\n",
    "  clf = LogisticRegression(random_state=0).fit(train_tmp[[i]], train_tmp[['export']])\n",
    "  train_tmp['unv_predicted_export'] = clf.predict_proba(train_tmp[[i]])[:,1]\n",
    "  val_tmp['unv_predicted_export'] = clf.predict_proba(val_tmp[[i]])[:,1]\n",
    "  ks = metrics(None, None, None, None, None, None)\n",
    "  ks_report_train = ks.KS_train(train_tmp['export'], train_tmp['unv_predicted_export'], train_tmp['weight'], bins = 10)\n",
    "  ks_report_val = ks.KS_train(val_tmp['export'], val_tmp['unv_predicted_export'], val_tmp['weight'], bins = 10)\n",
    "  ks_report_train = formatKSReport(ks_report_train)\n",
    "  ks_report_val = formatKSReport(ks_report_val)\n",
    "  train_ks = ks_report_train[ks_report_train['max_ks'] == '<']['ks'].values[0]\n",
    "  train_gini = ks_report_train['gini'].values[0]\n",
    "  val_ks = ks_report_val[ks_report_val['max_ks'] == '<']['ks'].values[0]\n",
    "  val_gini = ks_report_val['gini'].values[0]\n",
    "  train_ks_list.append(train_ks)\n",
    "  train_gini_list.append(train_gini)\n",
    "  val_ks_list.append(val_ks)\n",
    "  val_gini_list.append(val_gini)\n",
    "\n",
    "d = {'variable_name': list(train_final[predictors2].columns), 'train_ks': train_ks_list, 'val_ks': val_ks_list, 'train_gini': train_gini_list, 'val_gini': val_gini_list}\n",
    "ks_gini = pd.DataFrame(data = d)\n",
    "ks_gini['ks_diff'] = ks_gini['train_ks'] - ks_gini['val_ks']\n",
    "ks_gini['gini_diff'] = ks_gini['train_gini'] - ks_gini['val_gini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9c750617-ada5-48b5-8710-76130254a4cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9238dcf0-922f-4449-b5a0-ac136b2c0da9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "corr = train_final[predictors2].corr().abs().unstack().reset_index()\n",
    "corr.columns = ['x1', 'x2', 'correlation_coefficient']\n",
    "corr = corr[(corr['x1'] != corr['x2'])]\n",
    "hi_corr = corr[corr['correlation_coefficient'] >= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f237dcf7-42bb-484c-9fa7-d0666b302118",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(hi_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "51222ac6-92a9-4400-9c97-dad53c16e398",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictors3 = [\n",
    "'gctrs_ttl_signal_3yrs',\n",
    "'ind_gctrs_3yrs',\n",
    "'gctrs_cnt_unq_yrs',\n",
    "'npayexp',\n",
    "'sic4_score',\n",
    "'nloc',\n",
    "'gctrs_cnt_unq_customer_country',\n",
    "'nrectyp',\n",
    "'satis',\n",
    "'sales',\n",
    "'drp_paydex1_loc_decile',\n",
    "'location_growth_score',\n",
    "'ncomptype',\n",
    "'nimptexpt',\n",
    "'foreign_trade_buyer_ind',\n",
    "'location_cluster_score_k500',\n",
    "'miny_ownd_ind',\n",
    "'export_job_title_ind',\n",
    "'ba_sum_excl_12m',\n",
    "'loc_pct_rent_1',\n",
    "'sml_bus_ind',\n",
    "'loc_pct_comptype_g',\n",
    "'exp_prop_bus_nme_ind',\n",
    "'ucc_flng_3yr_cnt',\n",
    "'ba_count_info_src_12m',\n",
    "'chg_tot_emp',\n",
    "'inds_norm_pydx_scr',\n",
    "'drp_sales_loc_decile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "56f95784-ef1c-4c47-b086-eb084cbac961",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params = \"{'colsample_bylevel':np.random.randint(5,10)/10,'colsample_bytree':np.random.randint(5,10)/10,'learning_rate': np.random.choice([0.1 , 0.01 , 0.05 , 0.075]),'max_depth':np.random.randint(3,5),'min_child_weight':np.random.randint(5,10),'n_estimators': np.random.choice([300,400,500]),'subsample':np.random.randint(5,10)/10}\"\n",
    "\n",
    "rs3 = ks_search(50, params, train2[predictors3], train2['export'], train2['weight'], val2[predictors3], val2['export'], val2['weight'])\n",
    "rs3.randomsearch_KS()\n",
    "\n",
    "output_full3 = rs3.result_out\n",
    "hyper_param3 = pd.concat(output_full3)\n",
    "hyper_param3.columns = ['train', 'val', 'diff', 'event_rate', 'min_prob', 'max_prob', 'predicted_event_rate', 'hyper_param', 'iteration', 'best_n_tree']\n",
    "\n",
    "random_search_result3 = pd.concat([hyper_param3.drop(['hyper_param'], axis = 1), hyper_param3['hyper_param'].map(eval).apply(pd.Series)], axis = 1).reset_index()\n",
    "random_search_result3.columns = ['metric', 'train', 'val', 'diff', 'event_rate', 'min_prob', 'max_prob', 'predicted_event_rate', 'iteration', 'best_n_tree', 'colsample_bylevel', 'colsample_bytree', 'learning_rate', 'max_depth', 'min_child_weight', 'n_estimator', 'subsample']\n",
    "\n",
    "model3 = xgb.XGBClassifier(colsample_bylevel = 0.5, colsample_bytree = 0.6, learning_rate = 0.05, max_depth = 3, min_child_weight = 6, n_estimators = 400, subsample = 0.6)\n",
    "model3.fit(train2[predictors3], train2['export'], sample_weight = train2['weight'], eval_set = [(val2[predictors3], val2['export'], val2['weight'])], eval_metric = 'auc', early_stopping_rounds = 8)\n",
    "feature_list3 = list(model3.get_booster().feature_names)\n",
    "train2['predicted_export3'] = model3.predict_proba(train2[feature_list3], ntree_limit = model3.best_ntree_limit)[:,1]\n",
    "val2['predicted_export3'] = model3.predict_proba(val2[feature_list3], ntree_limit = model3.best_ntree_limit)[:,1]\n",
    "test2['predicted_export3'] = model3.predict_proba(test2[feature_list3], ntree_limit = model3.best_ntree_limit)[:,1]\n",
    "train2['predicted_export3'].mean(), val2['predicted_export3'].mean(), test2['predicted_export3'].mean()\n",
    "\n",
    "feat_imp3 = featureImportance(model3, train2[feature_list3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dd62d396-33da-4896-99ee-20e5f48dd3bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(feat_imp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e380cad-880e-4d61-932f-e7d2db272467",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ks3 = metrics(None, None, None, None, None, None)\n",
    "ks_report_train3 = ks3.KS_train(train2['export'], train2['predicted_export3'], train2['weight'], bins = 10)\n",
    "ks_report_val3 = ks3.KS_train(val2['export'], val2['predicted_export3'], val2['weight'], bins = 10)\n",
    "ks_report_test3 = ks3.KS_train(test2['export'], test2['predicted_export3'], test2['weight'], bins = 10)\n",
    "\n",
    "ks_report_train3 = formatKSReport(ks_report_train3)\n",
    "ks_report_val3 = formatKSReport(ks_report_val3)\n",
    "ks_report_test3 = formatKSReport(ks_report_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "47ae1578-2ebf-40a9-8f15-8696cd06c984",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c9259366-1022-456a-8280-dd82f0f791ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "554ff223-a986-4fa3-9760-286eec367196",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_report_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ca5f9476-8ccc-426d-ba52-ea042ba97aac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(model3, open('/dbfs/FileStore/sahayk/us_export_propensity/pickles/us_export_propensity_model_20210912.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b76e776b-14ce-42c0-bf9e-169893b5309e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_final = train2[non_predictors + feature_list3 + ['predicted_export3']]\n",
    "val_final = val2[non_predictors + feature_list3 + ['predicted_export3']]\n",
    "test_final = test2[non_predictors + feature_list3 + ['predicted_export3']]\n",
    "\n",
    "pd.concat([train_final, val_final, test_final], ignore_index = True).to_csv('/dbfs/FileStore/sahayk/us_export_propensity/output_data/us_export_propensity_model_output_20210912.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fdcadd85-07f5-4e44-a7ff-03e19771f391",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_features = list(feat_imp3['feature'])\n",
    "\n",
    "train_final['weight'] = 1\n",
    "fs = preprocess(train_final[final_features], train_final['export'],  train_final['weight'])\n",
    "fs.identify_all({'missing_threshold': 0.95, 'correlation_threshold': 0.90})\n",
    "\n",
    "binning_data = fs.iv_df.astype(str)\n",
    "binning_data.columns = ['variable_name', 'min_value', 'max_value', 'count', 'dist_count', 'event', 'event_rate', 'non_event', 'non_event_rate',\n",
    "                       'dist_event', 'dist_non_event', 'woe', 'force', 'iv_bin', 'iv_overall']\n",
    "binning_data2 = binning_data.drop(columns = 'force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2fc71ebe-c2bb-4e22-a639-151bcbb780a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(binning_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2d098769-6861-4844-a9f4-d1c0c309bf1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_ks_list = []\n",
    "val_ks_list = []\n",
    "train_gini_list = []\n",
    "val_gini_list = []\n",
    "for i in list(train_final[predictors3].columns):\n",
    "  print(\"[INFO] Variable Name: {}\".format(i))\n",
    "  train_tmp = train_final[~train_final[i].isna()]\n",
    "  val_tmp = val_final[~val_final[i].isna()]\n",
    "  clf = LogisticRegression(random_state=0).fit(train_tmp[[i]], train_tmp[['export']])\n",
    "  train_tmp['unv_predicted_export'] = clf.predict_proba(train_tmp[[i]])[:,1]\n",
    "  val_tmp['unv_predicted_export'] = clf.predict_proba(val_tmp[[i]])[:,1]\n",
    "  ks = metrics(None, None, None, None, None, None)\n",
    "  ks_report_train = ks.KS_train(train_tmp['export'], train_tmp['unv_predicted_export'], train_tmp['weight'], bins = 10)\n",
    "  ks_report_val = ks.KS_train(val_tmp['export'], val_tmp['unv_predicted_export'], val_tmp['weight'], bins = 10)\n",
    "  ks_report_train = formatKSReport(ks_report_train)\n",
    "  ks_report_val = formatKSReport(ks_report_val)\n",
    "  train_ks = ks_report_train[ks_report_train['max_ks'] == '<']['ks'].values[0]\n",
    "  train_gini = ks_report_train['gini'].values[0]\n",
    "  val_ks = ks_report_val[ks_report_val['max_ks'] == '<']['ks'].values[0]\n",
    "  val_gini = ks_report_val['gini'].values[0]\n",
    "  train_ks_list.append(train_ks)\n",
    "  train_gini_list.append(train_gini)\n",
    "  val_ks_list.append(val_ks)\n",
    "  val_gini_list.append(val_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bd7017e7-b43f-4319-86c5-286446914e52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "d = {'variable_name': list(train_final[predictors3].columns), 'train_ks': train_ks_list, 'val_ks': val_ks_list, 'train_gini': train_gini_list, 'val_gini': val_gini_list}\n",
    "ks_gini = pd.DataFrame(data = d)\n",
    "ks_gini['ks_diff'] = ks_gini['train_ks'] - ks_gini['val_ks']\n",
    "ks_gini['gini_diff'] = ks_gini['train_gini'] - ks_gini['val_gini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3da4780e-fe2e-4215-a257-48f878b598f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ks_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "83a41333-fd64-4792-8879-ff82c8daddc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02 Model Development",
   "notebookOrigID": 2348033467758212,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
